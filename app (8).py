# -*- coding: utf-8 -*-
"""Updated_Qwen_Azuresql_kothari_kothari.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G6rcyWkY3xq5u-ejfHUBhzEPgmJVXp50
"""

!pip install pytesseract
!apt-get update
!apt-get install -y tesseract-ocr
!pip install qwen_vl_utils
!pip install transformer
!pip install optimum[graphcore]
!pip install git+https://github.com/huggingface/transformer
!pip install auto-gptq
!pip install transformers==4.38.2
!pip install autoawq --upgrade # Upgrade autoawq to the latest version
!pip install gradio

!pip install transformers
from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor, AutoProcessor # Import AutoProcessor

model = Qwen2VLForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2-VL-2B-Instruct-AWQ", torch_dtype="auto", device_map="auto"
)

processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-2B-Instruct-AWQ")

!apt-get update
!apt-get install -y unixodbc-dev
!pip install pyodbc
!pip install sqlalchemy
!pip install azure-storage-blob

!apt-get update
!apt-get install -y unixodbc-dev
!pip install pyodbc sqlalchemy
!sudo apt update
!sudo apt install -y unixodbc-dev
!sudo apt install -y msodbcsql17

!sudo ACCEPT_EULA=Y apt-get install -y msodbcsql17

model = Qwen2VLForConditionalGeneration.from_pretrained(
    "Qwen/Qwen2-VL-2B-Instruct-AWQ",
    use_auth_token="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",
    torch_dtype="auto",
    device_map="auto"
)

!pip install pymssql

!curl ifconfig.me

!pip install --upgrade gradio

!pip install qwen_vl_utils

!pip install pytesseract pymssql

import gradio as gr
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info
import torch
import pandas as pd
import pytesseract
import cv2
import pymssql
import random

# Initialize model and processor
model = Qwen2VLForConditionalGeneration.from_pretrained("Qwen/Qwen2-VL-2B-Instruct", torch_dtype="auto")
if torch.cuda.is_available():
    model.to("cuda")

processor = AutoProcessor.from_pretrained("Qwen/Qwen2-VL-2B-Instruct")
pytesseract.pytesseract_cmd = r'/usr/bin/tesseract'

# Function to identify category based on keywords
def identify_category(text):
    """Identify service category based on keywords in the text."""
    text = text.lower()
    if any(keyword in text for keyword in ["food", "meal", "restaurant", "cafe", "coffee", "drink"]):
        return "Food"
    elif any(keyword in text for keyword in ["travel", "flight", "bus", "car", "taxi", "train", "ticket"]):
        return "Travel"
    elif any(keyword in text for keyword in ["hotel", "stay", "room", "resort", "accommodation"]):
        return "Stay"
    else:
        return "Others"

# Store DataFrame to Azure SQL Database using pymssql
def store_to_azure_sql(dataframe):
    """Store the generated DataFrame to Azure SQL Database using pymssql."""
    try:
        # Connect to Azure SQL Database
        conn = pymssql.connect(
            server="piosqlserverbd.database.windows.net",
            user="pio-admin",
            password="Poctest123#",
            database="PIOSqlDB"
        )
        cursor = conn.cursor()

        # Create the table if it doesn't exist
        create_table_query = """
        IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='Invoices' AND xtype='U')
        CREATE TABLE Invoices (
            EmployeeID NVARCHAR(50) NOT NULL PRIMARY KEY,
            InvoiceNumber NVARCHAR(255),
            Date NVARCHAR(255),
            Place NVARCHAR(255),
            Amount NVARCHAR(255),
            Category NVARCHAR(255),
            ApprovalStatus NVARCHAR(50) DEFAULT 'Pending'
        )
        """
        cursor.execute(create_table_query)

        # Get the last inserted EmployeeID to increment
        cursor.execute("SELECT TOP 1 EmployeeID FROM Invoices ORDER BY EmployeeID DESC")
        last_id = cursor.fetchone()
        next_id = 0 if last_id is None else int(last_id[0]) + 1

        # Insert data into the table
        for _, row in dataframe.iterrows():
            category = identify_category(row["Invoice Details"])
            insert_query = """
            INSERT INTO Invoices (EmployeeID, InvoiceNumber, Date, Place, Amount, Category, ApprovalStatus)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            """
            cursor.execute(
                insert_query,
                (
                    f"{next_id:03d}",  # Auto-increment EmployeeID
                    row.get("Invoice Number", "")[:255],  # Truncate to 255 characters
                    row.get("Date", ""),
                    row.get("Place", ""),
                    row.get("Amount", ""),
                    category,
                    "Pending"
                )
            )
            next_id += 1

        # Commit and close connection
        conn.commit()
        conn.close()

        return "Data successfully stored in Azure SQL Database."

    except Exception as e:
        return f"Error storing data to database: {e}"

# Function to preprocess the image for OCR
def preprocess_image(image_path):
    image = cv2.imread(image_path)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
    return binary

# Function to extract text using OCR
def ocr_extract_text(image_path):
    preprocessed_image = preprocess_image(image_path)
    return pytesseract.image_to_string(preprocessed_image)

# Function to process image and extract details
def process_image(model, processor, image_path):
    try:
        messages = [{
            "role": "user",
            "content": [
                {"type": "image", "image": image_path},
                {"type": "text", "text": (
                    "Extract the following details from the invoice:\n"
                    "- 'invoice_number'\n"
                    "- 'date'\n"
                    "- 'place'\n"
                    "- 'amount' (monetary value in the relevant currency)\n"
                    "- 'category' (based on the invoice type)"
                )}
            ]
        }]

        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = processor(text=[text], images=image_inputs, videos=video_inputs, padding=True, return_tensors="pt")
        inputs = inputs.to(model.device)

        generated_ids = model.generate(**inputs, max_new_tokens=128)
        generated_ids_trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]
        output_text = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)

        return parse_details(output_text[0])

    except Exception as e:
        print(f"Model failed, falling back to OCR: {e}")
        ocr_text = ocr_extract_text(image_path)
        return parse_details(ocr_text)

# Function to parse details from text
def parse_details(details):
    parsed_data = {
        "Invoice Number": None,
        "Date": None,
        "Place": None,
        "Amount": None,
        "Invoice Details": details
    }

    lines = details.split("\n")
    for line in lines:
        lower_line = line.lower()
        if "invoice" in lower_line:
            parsed_data["Invoice Number"] = line.split(":")[-1].strip()
        elif "date" in lower_line:
            parsed_data["Date"] = line.split(":")[-1].strip()
        elif "place" in lower_line:
            parsed_data["Place"] = line.split(":")[-1].strip()
        elif any(keyword in lower_line for keyword in ["total", "amount", "cost"]):
            parsed_data["Amount"] = line.split(":")[-1].strip()

    return parsed_data

# Gradio interface
def gradio_interface(image_files):
    results = []
    for image_file in image_files:
        details = process_image(model, processor, image_file)
        results.append(details)

    df = pd.DataFrame(results)
    status = store_to_azure_sql(df)
    return df, status

# Launch Gradio interface
grpc_interface = gr.Interface(
    fn=gradio_interface,
    inputs=gr.Files(label="Upload Invoice Images"),
    outputs=[gr.Dataframe(interactive=True), gr.Textbox(label="Database Storage Status")],
    title="Invoice Extraction with Approval Status",
)

import os
port = int(os.environ.get("PORT", 5000))
grpc_interface.launch(server_name="0.0.0.0", server_port=port)

!pip freeze > requirements.txt

import re

def adjust_dates(date):
    replacements = {'jan': '01', 'feb': '02', 'mar': '03', 'apr': '04', 'may': '05', 'jun': '06',
                    'jul': '07', 'aug': '08', 'sep': '09', 'oct': '10', 'nov': '11', 'dec': '12'}
    date = re.sub(r"[-']", "/", date.lower())
    for old, new in replacements.items():
        date = date.replace(old.lower(), new)
    return date

from datetime import datetime

df['dateofupload'] = '2025-01-25'

def append_currency(row):
    if not row['currency']:
        inferred_currency = infer_currency_from_address(row['address'])
        return f"{row['amount']} {inferred_currency}"
    else:
        return f"{row['amount']} {row['currency']}"

df['amount'] = df.apply(append_currency, axis=1)